{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4755bd58",
   "metadata": {},
   "source": [
    "\n",
    "# Preflight Tests — Stimulus Generator & Participant Schedule\n",
    "\n",
    "Run these cells **before** spending money on API calls. They verify:\n",
    "1) The *participant schedule* (`trials_participants.csv`) is well-formed.\n",
    "2) File paths point to real images and match their declared condition/label.\n",
    "3) **Shared-noise** guarantees hold (weak/strong use *identical* noise in mixture trials).\n",
    "4) **Signal math** checks out (`combined - noise == signal`).\n",
    "5) Basic distribution sanity (present rate ~ 0.5; strong assignment ~ uniform across P1–P3).\n",
    "\n",
    "> Assumes you've already run `export_trials_with_participants()` in your `ImageGen.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "TRIALS_PARTICIPANTS = Path(\"trials_participants.csv\")\n",
    "DATASET_ROOT = Path(\"perceptual_dataset_calibrated\")\n",
    "\n",
    "assert TRIALS_PARTICIPANTS.exists(), \"Missing trials_participants.csv — run export_trials_with_participants() first.\"\n",
    "assert DATASET_ROOT.exists(), f\"Missing dataset root: {DATASET_ROOT}\"\n",
    "print(\"[ok] Paths look good.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf0275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load schedule and run basic structure checks\n",
    "df = pd.read_csv(TRIALS_PARTICIPANTS)\n",
    "need = {\"TrialID\",\"Block\",\"ParticipantID\",\"Truth\",\"AssignedCondition\",\"Image\"}\n",
    "assert need.issubset(df.columns), f\"Missing columns. Need {need}, got {set(df.columns)}\"\n",
    "\n",
    "n_trials = df[\"TrialID\"].nunique()\n",
    "triplets_ok = (df.groupby(\"TrialID\").size() == 3).all()\n",
    "print(f\"[data] rows={len(df)} unique TrialID={n_trials} triplets_ok={triplets_ok}\")\n",
    "assert triplets_ok, \"Each TrialID must have exactly 3 participant rows\"\n",
    "\n",
    "display(df.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Equal block sanity\n",
    "eq = df[df[\"Block\"]==\"equal\"].copy()\n",
    "assert not eq.empty, \"No equal block rows found\"\n",
    "assert (eq[\"AssignedCondition\"]==\"equal\").all(), \"Equal block rows must have AssignedCondition == 'equal'\"\n",
    "\n",
    "# Presence prior near 0.5 on equal block (use tolerance for small N)\n",
    "p_eq = eq.drop_duplicates(\"TrialID\")[\"Truth\"].mean()\n",
    "print(f\"[equal] present rate ≈ {p_eq:.3f} (expect ~0.5)\")\n",
    "assert 0.3 <= p_eq <= 0.7, \"Equal-block present rate looks off\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0128f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Mixture absent: everyone sees same absent image (we schedule 'weak' path rows in CSV)\n",
    "mix_abs = df[(df[\"Block\"]==\"mixture\") & (df[\"Truth\"]==0)].copy()\n",
    "if mix_abs.empty:\n",
    "    print(\"[mixture/absent] no absent rows found — skipping check\")\n",
    "else:\n",
    "    assert (mix_abs[\"AssignedCondition\"]==\"weak\").all(),         \"Mixture-absent participant rows should consistently use 'weak' path in CSV (image is absent anyway)\"\n",
    "    # All 3 participants on the same TrialID should point to the same image path\n",
    "    same_img = (mix_abs.groupby(\"TrialID\")[\"Image\"].nunique() == 1).all()\n",
    "    print(f\"[mixture/absent] all 3 participants share the same absent image: {same_img}\")\n",
    "    assert same_img, \"Mixture-absent rows must reference the same image path per TrialID\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Mixture present: exactly one strong and two weak per TrialID\n",
    "mix_pre = df[(df[\"Block\"]==\"mixture\") & (df[\"Truth\"]==1)].copy()\n",
    "if mix_pre.empty:\n",
    "    print(\"[mixture/present] no present rows found — skipping check\")\n",
    "else:\n",
    "    ct = (mix_pre.groupby([\"TrialID\",\"AssignedCondition\"]).size()\n",
    "          .unstack(fill_value=0))\n",
    "    # Verify 1 strong + 2 weak per TrialID\n",
    "    ok_mask = (ct.get(\"strong\",0) == 1) & (ct.get(\"weak\",0) == 2)\n",
    "    ok_ratio = ok_mask.mean()\n",
    "    print(f\"[mixture/present] fraction of trials with 1 strong + 2 weak = {ok_ratio:.3f}\")\n",
    "    assert ok_mask.all(), \"Each mixture-present TrialID must have exactly 1 strong and 2 weak rows\"\n",
    "\n",
    "    # Uniformity of strong assignment across participants (rough check)\n",
    "    strong_pid_counts = (mix_pre[mix_pre[\"AssignedCondition\"]==\"strong\"]\n",
    "                         [\"ParticipantID\"].value_counts().sort_index())\n",
    "    print(\"[mixture/present] strong assignment counts by ParticipantID:\")\n",
    "    display(strong_pid_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55039db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Path integrity: files exist and paths match cond/label expectations\n",
    "from pathlib import Path\n",
    "\n",
    "def path_looks_right(row):\n",
    "    p = Path(row[\"Image\"])\n",
    "    if not p.exists():\n",
    "        return False\n",
    "    cond = row[\"AssignedCondition\"]\n",
    "    label = \"present\" if int(row[\"Truth\"])==1 else \"absent\"\n",
    "    # expected pattern: .../<cond>/<label>/combined/<cond>_<label>_<id>_combined.png\n",
    "    return (f\"/{cond}/{label}/combined/\" in str(p).replace(\"\\\\\",\"/\") \n",
    "            and f\"{cond}_{label}_\" in p.name)\n",
    "\n",
    "ok = df.apply(path_looks_right, axis=1)\n",
    "missing = (~ok).sum()\n",
    "print(f\"[paths] total={len(ok)} bad={missing}\")\n",
    "assert ok.all(), \"Some Image paths do not exist or do not match (cond/label)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4efb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Shared-noise tests: mixture-present and mixture-absent\n",
    "import numpy as np\n",
    "\n",
    "# helper to load noise npy given cond/label/tid\n",
    "def noise_npy_path(cond, label, tid):\n",
    "    return DATASET_ROOT/cond/label/\"noise\"/f\"{cond}_{label}_{tid:03d}_noise.npy\"\n",
    "\n",
    "# Sample a few mixture-present TrialIDs\n",
    "mix_pre_ids = mix_pre[\"TrialID\"].drop_duplicates().tolist() if not mix_pre.empty else []\n",
    "if mix_pre_ids:\n",
    "    samp = mix_pre_ids[: min(5, len(mix_pre_ids))]\n",
    "    for tid in samp:\n",
    "        w_path = noise_npy_path(\"weak\",\"present\",tid)\n",
    "        s_path = noise_npy_path(\"strong\",\"present\",tid)\n",
    "        assert w_path.exists() and s_path.exists(), f\"Missing noise npy for TrialID {tid}\"\n",
    "        w_noise = np.load(w_path); s_noise = np.load(s_path)\n",
    "        assert np.allclose(w_noise, s_noise), f\"Noise mismatch (weak vs strong) on TrialID {tid}\"\n",
    "    print(\"[noise] mixture-present: weak and strong share identical noise ✅\")\n",
    "else:\n",
    "    print(\"[noise] no mixture-present trials to test\")\n",
    "\n",
    "# Sample a few mixture-absent TrialIDs\n",
    "mix_abs_ids = mix_abs[\"TrialID\"].drop_duplicates().tolist() if not mix_abs.empty else []\n",
    "if mix_abs_ids:\n",
    "    samp = mix_abs_ids[: min(5, len(mix_abs_ids))]\n",
    "    for tid in samp:\n",
    "        w_path = noise_npy_path(\"weak\",\"absent\",tid)\n",
    "        s_path = noise_npy_path(\"strong\",\"absent\",tid)\n",
    "        if w_path.exists() and s_path.exists():\n",
    "            w_noise = np.load(w_path); s_noise = np.load(s_path)\n",
    "            assert np.allclose(w_noise, s_noise), f\"Absent noise mismatch on TrialID {tid}\"\n",
    "    print(\"[noise] mixture-absent: weak and strong share identical noise ✅\")\n",
    "else:\n",
    "    print(\"[noise] no mixture-absent trials to test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d31c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Signal math: check that combined - noise == signal (within float tolerance)\n",
    "def triple_paths(cond, label, tid):\n",
    "    base = DATASET_ROOT/cond/label\n",
    "    comb = base/\"combined\"/f\"{cond}_{label}_{tid:03d}_combined.npy\"\n",
    "    noi  = base/\"noise\"/f\"{cond}_{label}_{tid:03d}_noise.npy\"\n",
    "    sig  = base/\"signal\"/f\"{cond}_{label}_{tid:03d}_signal.npy\"\n",
    "    return comb, noi, sig\n",
    "\n",
    "def check_signal(cond, tid):\n",
    "    comb, noi, sig = triple_paths(cond, \"present\", tid)\n",
    "    assert comb.exists() and noi.exists() and sig.exists(), f\"Missing npy for {cond} {tid}\"\n",
    "    c = np.load(comb); n = np.load(noi); s = np.load(sig)\n",
    "    err = np.abs((c - n) - s).max()\n",
    "    return err\n",
    "\n",
    "checked_any = False\n",
    "for cond in [\"weak\",\"strong\",\"equal\"]:\n",
    "    # find present TrialIDs for this cond\n",
    "    tids = df[(df[\"AssignedCondition\"]==cond) & (df[\"Truth\"]==1)][\"TrialID\"].unique().tolist()\n",
    "    for tid in tids[:3]:\n",
    "        err = check_signal(cond, tid)\n",
    "        assert err < 1e-6, f\"Signal mismatch for {cond} {tid} (max abs err={err})\"\n",
    "        checked_any = True\n",
    "if checked_any:\n",
    "    print(\"[signal] combined - noise == signal on sampled present images ✅\")\n",
    "else:\n",
    "    print(\"[signal] no present images sampled for signal check\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Distribution checks\n",
    "eq_trials = df[df[\"Block\"]==\"equal\"].drop_duplicates(\"TrialID\")\n",
    "mix_trials = df[df[\"Block\"]==\"mixture\"].drop_duplicates(\"TrialID\")\n",
    "p_eq = eq_trials[\"Truth\"].mean() if not eq_trials.empty else float('nan')\n",
    "p_mix = mix_trials[\"Truth\"].mean() if not mix_trials.empty else float('nan')\n",
    "print(f\"[rates] equal present rate:   {p_eq:.3f}\")\n",
    "print(f\"[rates] mixture present rate: {p_mix:.3f}\")\n",
    "\n",
    "# Strong assignment uniformity across participants (rough)\n",
    "if not mix_pre.empty:\n",
    "    strong_pid = (mix_pre[mix_pre[\"AssignedCondition\"]==\"strong\"][\"ParticipantID\"]\n",
    "                  .value_counts().sort_index())\n",
    "    print(\"[uniformity] strong counts by ParticipantID:\")\n",
    "    display(strong_pid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5de52",
   "metadata": {},
   "source": [
    "\n",
    "## Next\n",
    "If all assertions passed:\n",
    "- Open **LLMRunner2.ipynb**.\n",
    "- Set `DRY_RUN = True` (or `DRY_RUN=1` in env).\n",
    "- Run a small subset first: `p1 = run_phase1(dfp, limit_trials=5)` then `p2 = run_phase2(p1)`.\n",
    "- Inspect `API_files/phase1_results.csv` and `API_files/phase2_results.csv`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
