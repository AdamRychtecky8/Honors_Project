{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0bb5de",
   "metadata": {},
   "source": [
    "\n",
    "# LLMRunner2 — Participant-Scheduled Two‑Phase Perceptual Task\n",
    "\n",
    "This runner consumes the generator-built schedule **`trials_participants.csv`** (from `export_trials_with_participants()` in your ImageGen),\n",
    "and executes **Phase 1 (independent)** and **Phase 2 (group revision)** for each **(TrialID, ParticipantID)** pairing.\n",
    "\n",
    "**Key differences vs. the legacy runner:**\n",
    "- No internal scheduling; **generator decides** trial presence/absence and mixture assignment.\n",
    "- One noise background per trial; mixture-present trials have **one strong** and **two weak** participants.\n",
    "- Minimal, lean loops that directly call providers based on `ParticipantID → provider/model` mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, base64, time, json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# APIs\n",
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Paths ---\n",
    "TRIALS_PARTICIPANTS_PATH = Path(os.getenv(\"TRIALS_PARTICIPANTS_PATH\", \"trials_participants.csv\"))\n",
    "RESULTS_DIR = Path(os.getenv(\"RESULTS_DIR\", \"API_files\"))\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PHASE1_CSV = RESULTS_DIR / \"phase1_results.csv\"\n",
    "PHASE2_CSV = RESULTS_DIR / \"phase2_results.csv\"\n",
    "CONSENSUS_CSV = RESULTS_DIR / \"phase2_consensus.csv\"\n",
    "\n",
    "# --- Models & keys ---\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "GEMINI_MODEL = os.getenv(\"GEMINI_MODEL\", \"gemini-2.0-flash-thinking-exp-01-21\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# --- Safety toggle (no network when True) ---\n",
    "DRY_RUN = bool(int(os.getenv(\"DRY_RUN\", \"0\")))\n",
    "\n",
    "# --- Participant mapping ---\n",
    "# Map ParticipantID -> (provider_kind, model)\n",
    "# Adjust as needed (e.g., use two distinct OpenAI models)\n",
    "PARTICIPANT_TO_PROVIDER = {\n",
    "    1: (\"OpenAI\", OPENAI_MODEL),\n",
    "    2: (\"OpenAI\", OPENAI_MODEL),\n",
    "    3: (\"Gemini\", GEMINI_MODEL),\n",
    "}\n",
    "\n",
    "print(f\"[cfg] participants_csv={TRIALS_PARTICIPANTS_PATH}\")\n",
    "print(f\"[cfg] results_dir={RESULTS_DIR}\")\n",
    "print(f\"[cfg] providers={{pid: prov for pid, prov in PARTICIPANT_TO_PROVIDER.items()}}\")\n",
    "print(f\"[cfg] models={{'openai': OPENAI_MODEL, 'gemini': GEMINI_MODEL}} dry_run={DRY_RUN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize clients\n",
    "openai_client = None\n",
    "gemini_model = None\n",
    "\n",
    "if not DRY_RUN:\n",
    "    if OPENAI_API_KEY:\n",
    "        openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    else:\n",
    "        raise RuntimeError(\"Missing OPENAI_API_KEY (or set DRY_RUN=1)\")\n",
    "\n",
    "    if GEMINI_API_KEY:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        gemini_model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "    else:\n",
    "        raise RuntimeError(\"Missing GEMINI_API_KEY (or set DRY_RUN=1)\")\n",
    "else:\n",
    "    print(\"[info] DRY_RUN=1 — API calls will be simulated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_image_b64(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def parse_confidence(text: str) -> int:\n",
    "    \"\"\"Extract the first integer 1..10 from the model output; -1 if parsing fails.\"\"\"\n",
    "    s = str(text).strip()\n",
    "    num = \"\"\n",
    "    for ch in s:\n",
    "        if ch.isdigit():\n",
    "            num += ch\n",
    "        elif num:\n",
    "            break\n",
    "    try:\n",
    "        val = int(num)\n",
    "        return val if 1 <= val <= 10 else -1\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def conf_to_pred(c: int) -> int:\n",
    "    \"\"\"Map 1–5 -> 0 (absent), 6–10 -> 1 (present).\"\"\"\n",
    "    return 1 if c >= 6 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5db515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a perceptual decision-maker. You will receive an 8-bit grayscale image (mid-gray ≈ 128).\\n\"\n",
    "    \"A luminance signal may or may not be present. The prior probability of signal presence is 50%.\"\n",
    ")\n",
    "\n",
    "PHASE1_INSTR = (\n",
    "    \"Decide if a faint luminance signal is present.\\n\"\n",
    "    \"Return ONLY one integer 1–10 (no other text):\\n\"\n",
    "    \"1 = very confident ABSENT ... 5 = low confidence ABSENT; 6 = low confidence PRESENT ... 10 = very confident PRESENT.\"\n",
    ")\n",
    "\n",
    "def phase2_instr(self_rating: int, others: Dict[str, int]) -> str:\n",
    "    other_txt = \", \".join([f\"{k}: {v}\" for k, v in others.items()]) if others else \"none\"\n",
    "    return (\n",
    "        \"You already responded independently. Now reconsider after seeing the others' initial ratings.\\n\"\n",
    "        f\"Your initial rating: {self_rating}. Others: {other_txt}.\\n\"\n",
    "        \"Return ONLY one integer 1–10.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591de908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_openai_phase1(image_path: str, model: str = OPENAI_MODEL):\n",
    "    if DRY_RUN:\n",
    "        c = int(np.random.choice(range(1, 11)))\n",
    "        return str(c), c\n",
    "    img_b64 = encode_image_b64(image_path)\n",
    "    resp = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": PHASE1_INSTR},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{img_b64}\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=6, temperature=0\n",
    "    )\n",
    "    out = (resp.choices[0].message.content or \"\").strip()\n",
    "    return out, parse_confidence(out)\n",
    "\n",
    "def call_openai_phase2(image_path: str, self_rating: int, others: Dict[str, int], model: str = OPENAI_MODEL):\n",
    "    if DRY_RUN:\n",
    "        peer = int(round(np.mean(list(others.values())))) if others else self_rating\n",
    "        c = int(np.clip(round((self_rating + peer)/2), 1, 10))\n",
    "        return str(c), c\n",
    "    img_b64 = encode_image_b64(image_path)\n",
    "    resp = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": phase2_instr(self_rating, others)},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{img_b64}\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=6, temperature=0\n",
    "    )\n",
    "    out = (resp.choices[0].message.content or \"\").strip()\n",
    "    return out, parse_confidence(out)\n",
    "\n",
    "def call_gemini_phase1(image_path: str):\n",
    "    if DRY_RUN:\n",
    "        c = int(np.random.choice(range(1, 11)))\n",
    "        return str(c), c\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    prompt = SYSTEM_PROMPT + \"\\n\\n\" + PHASE1_INSTR\n",
    "    resp = gemini_model.generate_content([prompt, img])\n",
    "    out = (resp.text or \"\").strip()\n",
    "    return out, parse_confidence(out)\n",
    "\n",
    "def call_gemini_phase2(image_path: str, self_rating: int, others: Dict[str, int]):\n",
    "    if DRY_RUN:\n",
    "        peer = int(round(np.mean(list(others.values())))) if others else self_rating\n",
    "        c = int(np.clip(round((self_rating + peer)/2), 1, 10))\n",
    "        return str(c), c\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    prompt = SYSTEM_PROMPT + \"\\n\\n\" + phase2_instr(self_rating, others)\n",
    "    resp = gemini_model.generate_content([prompt, img])\n",
    "    out = (resp.text or \"\").strip()\n",
    "    return out, parse_confidence(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f78450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_trials_participants(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing {path}. Run export_trials_with_participants() in ImageGen.py first.\")\n",
    "    df = pd.read_csv(path)\n",
    "    need = {\"TrialID\",\"Block\",\"ParticipantID\",\"Truth\",\"AssignedCondition\",\"Image\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise ValueError(f\"{path} must contain {need}. Got: {list(df.columns)}\")\n",
    "    root = Path.cwd()\n",
    "    def _to_abs(p: str) -> str:\n",
    "        pth = Path(str(p))\n",
    "        return str(pth if pth.is_absolute() else (root / pth).resolve())\n",
    "    df[\"Image\"] = df[\"Image\"].astype(str).map(_to_abs)\n",
    "    for c in [\"TrialID\",\"ParticipantID\",\"Truth\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(int)\n",
    "    df[\"AssignedCondition\"] = df[\"AssignedCondition\"].astype(str)\n",
    "    df[\"Block\"] = df[\"Block\"].astype(str)\n",
    "    print(f\"[data] loaded {len(df)} participant-rows across {df['TrialID'].nunique()} trials\")\n",
    "    display(df.head(3))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_phase1(dfp: pd.DataFrame, limit_trials: int | None = None) -> pd.DataFrame:\n",
    "    if limit_trials is not None:\n",
    "        keep_tids = dfp[\"TrialID\"].drop_duplicates().head(limit_trials).tolist()\n",
    "        dfp = dfp[dfp[\"TrialID\"].isin(keep_tids)]\n",
    "\n",
    "    rows = []\n",
    "    it = dfp.itertuples(index=False)\n",
    "    for r in tqdm(it, total=len(dfp), desc=\"Phase 1 — independent (participants)\"):\n",
    "        tid   = int(r.TrialID)\n",
    "        pid   = int(r.ParticipantID)\n",
    "        truth = int(r.Truth)\n",
    "        img   = str(r.Image)\n",
    "        assigned = str(r.AssignedCondition)  # equal/weak/strong\n",
    "        prov_kind, model = PARTICIPANT_TO_PROVIDER[pid]\n",
    "\n",
    "        t0 = time.time()\n",
    "        if prov_kind == \"OpenAI\":\n",
    "            raw, conf = call_openai_phase1(img, model=model)\n",
    "        else:\n",
    "            raw, conf = call_gemini_phase1(img)\n",
    "        lat = round(time.time() - t0, 3)\n",
    "\n",
    "        pred = conf_to_pred(conf) if 1 <= conf <= 10 else -1\n",
    "        correct = int(pred == truth) if pred in (0,1) else 0\n",
    "\n",
    "        rows.append({\n",
    "            \"phase\": 1,\n",
    "            \"TrialID\": tid,\n",
    "            \"ParticipantID\": pid,\n",
    "            \"Truth\": truth,\n",
    "            \"Image\": img,\n",
    "            \"provider\": f\"P{pid}\",\n",
    "            \"provider_kind\": prov_kind,\n",
    "            \"model\": model,\n",
    "            \"assigned_condition\": assigned,\n",
    "            \"raw\": raw,\n",
    "            \"confidence\": conf,\n",
    "            \"pred\": pred,\n",
    "            \"correct\": correct,\n",
    "            \"latency_s\": lat,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_phase2(p1: pd.DataFrame) -> pd.DataFrame:\n",
    "    if p1 is None or p1.empty:\n",
    "        raise ValueError(\"Phase 1 results are required for Phase 2.\")\n",
    "\n",
    "    rows = []\n",
    "    for tid, grp in tqdm(p1.groupby(\"TrialID\"), total=p1[\"TrialID\"].nunique(),\n",
    "                         desc=\"Phase 2 — discussion (participants)\"):\n",
    "        truth = int(grp[\"Truth\"].iloc[0])\n",
    "        # initial ratings per participant (P1/P2/P3)\n",
    "        initial = {}\n",
    "        for _, rr in grp.iterrows():\n",
    "            pid = int(rr[\"ParticipantID\"])\n",
    "            conf = int(rr[\"confidence\"]) if pd.notna(rr[\"confidence\"]) else -1\n",
    "            if 1 <= conf <= 10:\n",
    "                initial[f\"P{pid}\"] = conf\n",
    "\n",
    "        # each participant revises\n",
    "        for _, rr in grp.iterrows():\n",
    "            pid = int(rr[\"ParticipantID\"])\n",
    "            img = str(rr[\"Image\"])\n",
    "            prov_kind = rr[\"provider_kind\"]\n",
    "            model = rr[\"model\"]\n",
    "\n",
    "            self_key = f\"P{pid}\"\n",
    "            self_conf = initial.get(self_key, -1)\n",
    "            others = {k:v for k,v in initial.items() if k != self_key}\n",
    "\n",
    "            t0 = time.time()\n",
    "            if prov_kind == \"OpenAI\":\n",
    "                raw, conf = call_openai_phase2(img, self_conf, others, model=model)\n",
    "            else:\n",
    "                raw, conf = call_gemini_phase2(img, self_conf, others)\n",
    "            lat = round(time.time() - t0, 3)\n",
    "\n",
    "            pred = conf_to_pred(conf) if 1 <= conf <= 10 else -1\n",
    "            correct = int(pred == truth) if pred in (0,1) else 0\n",
    "\n",
    "            rows.append({\n",
    "                \"phase\": 2,\n",
    "                \"TrialID\": int(tid),\n",
    "                \"ParticipantID\": pid,\n",
    "                \"Truth\": truth,\n",
    "                \"Image\": img,\n",
    "                \"provider\": f\"P{pid}\",\n",
    "                \"provider_kind\": prov_kind,\n",
    "                \"model\": model,\n",
    "                \"raw\": raw,\n",
    "                \"confidence\": conf,\n",
    "                \"pred\": pred,\n",
    "                \"correct\": correct,\n",
    "                \"latency_s\": lat,\n",
    "                \"initial_confidence\": self_conf,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e1077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def majority_from_confidences(conf_list):\n",
    "    bins = [conf_to_pred(c) for c in conf_list if 1 <= int(c) <= 10]\n",
    "    if not bins:\n",
    "        return -1\n",
    "    ones = sum(bins)\n",
    "    zeros = len(bins) - ones\n",
    "    if ones > zeros: return 1\n",
    "    if zeros > ones: return 0\n",
    "    return -1  # tie\n",
    "\n",
    "def consensus_from_phase2(p2: pd.DataFrame) -> pd.DataFrame:\n",
    "    if p2 is None or p2.empty:\n",
    "        return pd.DataFrame()\n",
    "    agg = (\n",
    "        p2.groupby(\"TrialID\")\n",
    "          .agg({\n",
    "              \"Truth\":\"first\",\"Image\":\"first\",\n",
    "              \"confidence\": list\n",
    "          })\n",
    "          .reset_index()\n",
    "    )\n",
    "    agg[\"consensus_pred\"] = agg[\"confidence\"].apply(majority_from_confidences)\n",
    "    agg[\"consensus_correct\"] = (agg[\"consensus_pred\"] == agg[\"Truth\"]).astype(int)\n",
    "    return agg[[\"TrialID\",\"Truth\",\"Image\",\"consensus_pred\",\"consensus_correct\"]]\n",
    "\n",
    "def summarize_phase(df: pd.DataFrame, title: str):\n",
    "    if df is None or df.empty:\n",
    "        print(f\"[warn] no results for {title}\"); return\n",
    "    d = df.copy()\n",
    "    d = d[(d[\"confidence\"]>=1) & (d[\"confidence\"]<=10)]\n",
    "    d[\"pred\"] = (d[\"confidence\"]>=6).astype(int)\n",
    "    d[\"correct\"] = (d[\"pred\"]==d[\"Truth\"]).astype(int)\n",
    "\n",
    "    overall = d.groupby(\"provider\")[\"correct\"].mean().rename(\"accuracy\").to_frame().reset_index()\n",
    "    by_assigned = d.groupby([\"provider\",\"assigned_condition\"])[\"correct\"].mean().rename(\"accuracy\").to_frame().reset_index()\n",
    "    by_kind = d.groupby(\"provider_kind\")[\"correct\"].mean().rename(\"accuracy\").to_frame().reset_index()\n",
    "\n",
    "    print(f\"=== {title} ===\")\n",
    "    display(overall); display(by_assigned); display(by_kind)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "    axes[0].set_title(\"Overall accuracy\")\n",
    "    axes[0].bar(overall[\"provider\"], overall[\"accuracy\"]); axes[0].set_ylim(0, 1)\n",
    "\n",
    "    pv = by_assigned.pivot(index=\"assigned_condition\", columns=\"provider\", values=\"accuracy\").fillna(0)\n",
    "    pv.plot(kind=\"bar\", ax=axes[1], title=\"Accuracy by assigned condition\", ylim=(0, 1))\n",
    "\n",
    "    pv2 = d.groupby([\"provider\",\"Truth\"])[\"confidence\"].mean().rename(\"mean_conf\").to_frame().reset_index().replace({\"Truth\":{0:\"absent\",1:\"present\"}})\n",
    "    pv2 = pv2.pivot(index=\"Truth\", columns=\"provider\", values=\"mean_conf\").reindex([\"absent\",\"present\"])\n",
    "    pv2.plot(kind=\"bar\", ax=axes[2], title=\"Mean confidence by truth\", ylim=(1, 10))\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "def summarize_delta(p1: pd.DataFrame, p2: pd.DataFrame):\n",
    "    if p1 is None or p2 is None or p1.empty or p2.empty:\n",
    "        print(\"[warn] need both phases for delta\"); return\n",
    "    a = p1[[\"TrialID\",\"provider\",\"confidence\"]].rename(columns={\"confidence\":\"conf1\"})\n",
    "    b = p2[[\"TrialID\",\"provider\",\"confidence\"]].rename(columns={\"confidence\":\"conf2\"})\n",
    "    m = a.merge(b, on=[\"TrialID\",\"provider\"], how=\"inner\")\n",
    "    m[\"delta\"] = m[\"conf2\"] - m[\"conf1\"]\n",
    "    print(\"Change in confidence (phase2 - phase1):\")\n",
    "    display(m.groupby(\"provider\")[\"delta\"].describe().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% One-Click Run (uncomment to execute end-to-end)\n",
    "# dfp = load_trials_participants(TRIALS_PARTICIPANTS_PATH)\n",
    "# p1 = run_phase1(dfp, limit_trials=None)  # set an int to smoke-test\n",
    "# p1.to_csv(PHASE1_CSV, index=False)\n",
    "# summarize_phase(p1, \"Phase 1 — Independent\")\n",
    "#\n",
    "# p2 = run_phase2(p1)\n",
    "# p2.to_csv(PHASE2_CSV, index=False)\n",
    "# summarize_phase(p2, \"Phase 2 — Discussion\")\n",
    "# summarize_delta(p1, p2)\n",
    "#\n",
    "# consensus = consensus_from_phase2(p2)\n",
    "# consensus.to_csv(CONSENSUS_CSV, index=False)\n",
    "# print(f\"[ok] wrote consensus to {CONSENSUS_CSV}  (rows={len(consensus)})\")\n",
    "# display(consensus.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c90c4",
   "metadata": {},
   "source": [
    "\n",
    "### Optional sanity checks (manual)\n",
    "- Confirm each *mixture-present* TrialID in `trials_participants.csv` has exactly **one** `AssignedCondition == \"strong\"` and **two** `\"weak\"` rows (same `TrialID`, different `ParticipantID`).\n",
    "- Confirm all three participant rows for a `TrialID` reference images derived from the **same noise background** (guaranteed by the generator).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
